---
title: "Wildfires Competition"
subtitle: "GO Bayes!"
author: "Eric"
date: "26/4/2021"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, comment = NA)
```

# Data loading

First load the data, add a column with site name, and one with a date 
```{r librairies, cache = FALSE}
rm(list=ls())
source("code_chargement_donnees.R")
```

There are $3503$ sites that are measured during $7$ months during $23$ years, which makes $563983$ records.


And group by site to explore the data
```{r}
d <- data_train_DF %>% group_by(site) %>% 
  summarize(lat=mean(lat),lon=mean(lon),CNTmax=max(CNT, na.rm=T), CNTmean=mean(CNT, na.rm=T),
            BAmax=max(BA, na.rm=T), BAmean=mean(BA, na.rm=T)) %>%
  arrange(desc(CNTmean) ) %>%relocate(lat,lon, .after= BAmean) %>% tibble()
head(d)

d %>% ggplot(aes(y=log(1+CNTmean), x=log(1+BAmean)))+geom_point()+geom_smooth(se=0)
#data_train_DF%>% filter(month %in% c(5,6) ) %>% ggplot(aes(y=log(1+CNT), x=log(1+BA)))+geom_point()+geom_smooth(se=0)
```


# Data formatting

## Binning discrete variables

We recode the number of fires and their damages using their categorical values given by u_ba and u_cnt. As max(u_ba) is geater than max(data_train_DF) we add one extremal category. We now consider 29 bins.
```{r}
#u_baprim=c(-1,u_ba)
#cut(0,u_baprim, labels=F)
#cut(60000,u_baprim, labels=F)
#cut(NA,u_baprim, labels=F)
cut_modif <- function(feux=0,u=u_ba){
  uprim=c(-1,u)
  ifelse(is.na(feux),yes=feux, no= cut(feux,uprim, labels=F))
}

data_train_DF<- data_train_DF %>% 
  mutate(BAcontinuous=BA,
         CNTcontinuous=CNT) %>% 
  mutate(tetha_BA=cut_modif(feux=BA,u=c(u_ba,1000000)),
                    theta_CNT=cut_modif(feux=CNT,u=c(u_cnt,1000))     ) 
data_train_DF %>% pull(theta_CNT) %>% table()->tab
prior_CNT= cumsum(tab/sum(tab))
prior_CNT
```

## Spatial coherences

```{r}
decoupe= c(0.0, 0.1, 0.2 ,0.3, 0.4, 0.5, 0.75, 0.9, 0.95, 0.99, 1.0)
data_train_DF %>% group_by(site) %>% summarize(lon=mean(lon), lat=mean(lat) , CNT=mean(CNT, na.rm=T)) %>% pull(CNT) %>% quantile(prob=decoupe) %>% as.numeric->ubis
d<- data_train_DF %>% group_by(site) %>% summarize(lon=mean(lon), lat=mean(lat) , CNT=mean(CNT, na.rm=T), BA=mean(BA, na.rm=T)) %>% mutate(classe_CNT= cut_modif(CNT,u=ubis) ) 
d %>%  ggplot(aes(x=lon, y=lat))+
  geom_tile(aes(fill=-classe_CNT), color="black")+
  theme(legend.position="none") +
  labs(title="Grouping means of Wildfires Counts", x="Longitude", y="Latitude")+
  scale_fill_gradientn(colours = heat.colors(length(decoupe)))
  
```


```{r}
decoupe= c(0.0, 0.1, 0.2 ,0.3, 0.4, 0.5, 0.75, 0.9, 0.95, 0.99, 1.0)
d %>% pull(BA) %>% quantile(prob=decoupe) %>% as.numeric->ubis

d <- d %>% mutate(classe_BA= cut_modif(BA,u=ubis) ) 

d %>%  ggplot(aes(x=lon, y=lat))+
  geom_tile(aes(fill=-classe_BA), color="black")+
  theme(legend.position="none") +
  labs(title="Grouping means of Wildfires Burnt Areas", x="Longitude", y="Latitude")+
  scale_fill_gradientn(colours = heat.colors(length(decoupe)))
  
```

Adding the classes for BA and CNT to the main file

```{r}
d<-d %>% rename(mean_CNT=CNT, mean_BA=BA,
                classe_meanCNT=classe_CNT,
                classe_meanBA=classe_BA)
data_train_DF<-data_train_DF %>% left_join(d)
rm(d)
```

## Looking for spatial neighbors

We create variables nbcolat and nbcolong that say how may sites can be found with the same latitude (or with the same longitude) at a given time.
```{r}
d <- data_train_DF %>% dplyr::select(IdNumber,site,lat,lon,date,theta_CNT,tetha_BA)
d<-d %>% arrange(date,lon,lat)
d %>% group_by(date,lon) %>% summarise(nbcolong=length(lat)) %>% 
  ungroup() -> dcolong
d %>% group_by(date,lat) %>% summarise(nbcolat=length(lon)) %>% 
  ungroup() -> dcolat
d<-d %>% left_join(dcolat) %>% left_join(dcolong)
```

We first arrange by date and longitude followed by latitude. There is 7 months $\times$ 23 years $\times$ 117 = 18837 blocs of different latitudes. In this setting, one goes from left to right (following increasing longitudes) and then from bottom to top (following increasing latitudes). The regular structure of the lattice allows for a quick evaluation of the closest neighbors belonging to the same longitude.
```{r}
d<-d %>% arrange(date,lon,lat)%>% rowid_to_column(var="IdLat") 
nsites <- 3503
delta_up<- delta_bottom <- rep(0,nsites)
e=1
repeat {
colong=d$nbcolong[e]
delta_bottom[e]=0
delta_up[e+colong-1]= 0
if(colong!=1){
delta_bottom[(e+1):(e+colong-1)]=-1
delta_up[(e):(e+colong-2)]= 1
}
e=e+colong
if (e >=(nsites+1)){
break
}
}
d$IdNumber_down=d$IdNumber[d$IdLat+rep(delta_bottom, 161)]  
d$IdNumber_up=d$IdNumber[d$IdLat+rep(delta_up, 161)] 

# a bad computational idea is as follows
# E <- length(d$lat)
# right_neigbor<-rep(NA,E)
# left_neigbor<-rep(NA,E)
# up_neigbor<-rep(NA,E)
# down_neigbor<-rep(NA,E)
# for(e in 1:E) {
#   lat<-d$lat[e]
#   long<-d$lon[e]
#   dat=d$date[e]
#   e_right<-which((d$date==dat)&(d$lat==lat)&(d$long==long+0.5))
#   e_left<-which((d$date==dat)&(d$lat==lat)&(d$long==long-0.5))
#   e_up<-which((d$date==dat)&(d$lat==lat+0.5)&(d$long==long))
#   e_down<-which((d$date==dat)&(d$lat==lat-0.5)&(d$long==long))
#   
#   right_neigbor[e]=ifelse(length(e_right)!=0,e_right,NA )
#   left_neigbor[e]= ifelse(length(e_left)!=0,e_left,NA )
#    up_neigbor[e]= ifelse(length(e_up)!=0,e_up,NA )
#     down_neigbor[e]=ifelse(length(e_down)!=0,e_down,NA )
#     
# 
# }
```

We can work the same way with neighbors belonging to the same latitude
```{r}
d<-d %>% arrange(date,lat,lon)%>% rowid_to_column(var="IdLong") 
nsites <- 3503
delta_left<- delta_right <- rep(0,nsites)
e=1
repeat {
colat=d$nbcolat[e]
delta_left[e]=0
delta_right[e+colong-1]= 0
if(colat!=1){
delta_left[(e+1):(e+colat-1)]=-1
delta_right[(e):(e+colat-2)]= 1
}
e=e+colat
if (e >=(nsites+1)){
break
}
}
d$IdNumber_left=d$IdNumber[d$IdLong+rep(delta_left, 161)]  
d$IdNumber_right=d$IdNumber[d$IdLong+rep(delta_right, 161)] 


data_train_DF<- data_train_DF %>% left_join(d %>% dplyr::select(starts_with("IdNumber")))
```

One can check that the neighbors seem correctly identified...

```{r}
sixselections <-sample(data_train_DF$IdNumber,6,rep=F)
ens=NULL
for(s in sixselections){ens=c(ens,data_train_DF %>% filter(IdNumber==s) %>% dplyr::select(starts_with("IdNum")) %>% as.vector() ) }
d<-data_frame(IdNumber=as.numeric(ens),coul=rep(1:6,each=5)) %>% left_join(data_train_DF %>% dplyr::select(IdNumber,lat,lon))
data_train_DF %>%  ggplot(aes(x=lon, y=lat))+
  geom_tile(color="black", fill="white")+geom_tile(data=d,fill=as.factor(d$coul))
```


```{r}
check_neighbor <- function(id,voisin,V_id,V_voisin){
  ifelse(abs(V_id-V_voisin) > 0.51, yes=id, no=voisin)
}
# voisin<-data_train_DF$IdNumber_left
# V_voisin= data_train_DF$lon[voisin]
# id=data_train_DF$IdNumber
# V_id=data_train_DF$lon
#sum(check_neighbor(id,voisin,V_id,V_voisin) != voisin)

data_train_DF<- data_train_DF %>%
  mutate(IdNumber_left=check_neighbor(IdNumber,IdNumber_left,lon,lon[IdNumber_left])) %>% 
  mutate(IdNumber_right=check_neighbor(IdNumber,IdNumber_right,lon,lon[IdNumber_right])) %>%        
  mutate(IdNumber_down=check_neighbor(IdNumber,IdNumber_down,lat,lat[IdNumber_down])) %>%
  mutate(IdNumber_left=check_neighbor(IdNumber,IdNumber_up,lat,lat[IdNumber_up])) 
  
```

## Looking for temporal neighbors

```{r}
data_train_DF %>% group_by(date,classe_meanCNT) %>% summarise(CNT=mean(CNT,na.rm=T)) %>%  ggplot(aes(x=date,y=log(CNT+1), color=as.factor(classe_meanCNT) ))+
  geom_line()+geom_smooth(se=0)+ theme(legend.position="none") +
  labs(title="Time evolution of Wildfires Counts", x="Date")

data_train_DF %>% group_by(month,classe_meanBA) %>% summarise(CNT=mean(CNT,na.rm=T)) %>%  ggplot(aes(x=month,y=CNT, color=as.factor(classe_meanBA) ))+
  geom_line()+ theme(legend.position="none") +
  labs(title="Monthly evolution of mean Wildfires Counts by classes of Burnt Areas", x="Month")
```


```{r}
data_train_DF %>% group_by(date,classe_meanBA) %>% summarise(BA=mean(BA,na.rm=T)) %>%  ggplot(aes(x=date,y=log(BA+1), color=as.factor(classe_meanBA) ))+
  geom_line()+geom_smooth(se=0)+ theme(legend.position="none") +
  labs(title="Time evolution of Wildfires Burnt areas", x="Date")

data_train_DF %>% group_by(month,classe_meanCNT) %>% summarise(BA=mean(BA,na.rm=T)) %>%  ggplot(aes(x=month,y=BA, color=as.factor(classe_meanCNT) ))+
  geom_line()+ theme(legend.position="none") +
  labs(title="Monthly evolution of mean Wildfires Burnt Areas by classes of Fire Counts", x="Month")
```

We now try to get the previous time record at a given spatio-temporal record, as well as the next one. If it appears to be the first month in the year the spatio-temporal record is its own previous neighbour. The point is its own next time neighbour if it correspond to the last month in the year.

```{r}
d <- data_train_DF %>% dplyr::select(IdNumber,site,lat,lon,date,month,year)
d<-d %>% arrange(lon,lat,date) %>% rowid_to_column(var="IdTime") %>% 
  mutate(IdTime=as.integer(IdTime))

delta_next <-rep(c(rep(1,each=6),0),each=80569)
d$IdNumber_next=d$IdNumber[d$IdTime+delta_next]  

delta_previous <- rep(c(0,rep(-1,each=6)),each=80569)
d$IdNumber_previous=d$IdNumber[d$IdTime+delta_previous]  

data_train_DF<- data_train_DF %>% left_join(d %>% dplyr::select(starts_with("IdNumber")))



```

# Reprise des calculs de David

```{r}
df<-data_train_DF %>% dplyr::select(starts_with("IdNumber"), 
                        site,lon,lat,month, year,BAcontinuous,CNTcontinuous) %>% 
  rename(BA=BAcontinuous,CNT=CNTcontinuous)

#Avec tout le fichier
dfpourDavid1= df %>% mutate(CNTimoins1=ifelse(month==3, yes= NA, no= CNT[IdNumber_previous]) ) %>% 
mutate(CNTiplus1=ifelse(month==9, yes= NA, no= CNT[IdNumber_next]) ) %>% mutate(CNTimoyen=rowMeans(dplyr::select(.,starts_with("CNTi")),na.rm=T)) %>% 
  mutate(XiL=ifelse(IdNumber==IdNumber_left,yes=NA, no= CNT[IdNumber_left])) %>% 
  mutate(XiR=ifelse(IdNumber==IdNumber_right,yes=NA, no= CNT[IdNumber_right])) %>% 
 mutate(XiU=ifelse(IdNumber==IdNumber_up,yes=NA, no= CNT[IdNumber_up])) %>%
  mutate(XiD=ifelse(IdNumber==IdNumber_down,yes=NA, no= CNT[IdNumber_down])) %>% 
  mutate(Xmoyen=rowMeans(dplyr::select(.,starts_with("Xi")),na.rm=T)) 
 
 dfpourDavid1 %>% 
  dplyr::select(CNT,Xmoyen,CNTimoyen) %>%  gather(-CNT,key="Transformes", value="values") %>% ggplot(aes(x=log(1+CNT),y=log(1+values)))+geom_point()+facet_wrap(~Transformes)+geom_smooth(se=0)

# Avec le fichier test
 # remove rows with data to predict:
train_DF = df[!is.na(df$CNT),]
test_DF = df[is.na(df$CNT),]
# remove BA (which contains more NA values):
train_DF = subset(train_DF, select = -BA)
# in test data, remove BA and the NA column of CNT:
test_DF = subset(test_DF, select = -c(CNT, BA))
dim(train_DF)
dim(test_DF)
dim(train_DF) # dimension of training data
  
set.seed(1)
SelNum<-sample(1:nrow(train_DF), round(0.5*nrow(train_DF)), replace=F)
train_select_DF<-train_DF[-c(SelNum),]
test_select_DF<-train_DF[c(SelNum),]

# Le fichier de travail pour l'apprentissage est le suivant
dim(train_select_DF)
train_select_IDNUMBERS= train_select_DF %>% pull(IdNumber)
length(train_select_IDNUMBERS)

# On fait le m^me boulot que précedemment mais on dit que CNT= NA si IDNumber n'est pas dans le training set

df<-data_train_DF %>% dplyr::select(starts_with("IdNumber"), 
                        site,lon,lat,month, year,BAcontinuous,CNTcontinuous) %>% 
  mutate(CNT=ifelse(IdNumber %in% train_select_IDNUMBERS, yes= CNTcontinuous, no= NA) )%>% 
           mutate(BA=BAcontinuous)

dfpourDavid2= df %>% mutate(CNTimoins1=ifelse(month==3, yes= NA, no= CNT[IdNumber_previous]) ) %>% 
mutate(CNTiplus1=ifelse(month==9, yes= NA, no= CNT[IdNumber_next]) ) %>% mutate(CNTimoyen=rowMeans(dplyr::select(.,starts_with("CNTi")),na.rm=T)) %>% 
  mutate(XiL=ifelse(IdNumber==IdNumber_left,yes=NA, no= CNT[IdNumber_left])) %>% 
  mutate(XiR=ifelse(IdNumber==IdNumber_right,yes=NA, no= CNT[IdNumber_right])) %>% 
 mutate(XiU=ifelse(IdNumber==IdNumber_up,yes=NA, no= CNT[IdNumber_up])) %>%
  mutate(XiD=ifelse(IdNumber==IdNumber_down,yes=NA, no= CNT[IdNumber_down])) %>% 
  mutate(Xmoyen=rowMeans(dplyr::select(.,starts_with("Xi")),na.rm=T)) 

train_select_DF=train_select_DF %>% left_join(dfpourDavid2 %>% 
                                                filter(IdNumber %in% train_select_IDNUMBERS ) )

# Le probleme c'est que tu perds en gros la moitié de ta base car il y des NaN (Not a Number) qui viennent du fait que  mean(c(NA,NA),na.rm=T)= NaN !!!
sum(is.nan(train_select_DF$Xmoyen))+sum(is.nan(train_select_DF$CNTimoyen))

# Mais il t'en reste pas mal
train_select_DF %>% 
  dplyr::select(CNT,Xmoyen,CNTimoyen) %>%  gather(-CNT,key="Transformes", value="values") %>% ggplot(aes(x=log(1+CNT),y=log(1+values)))+geom_point()+facet_wrap(~Transformes)+geom_smooth(se=0)


```


# Bayesian Updating

## Bayesian updating in theory


Let's call $\theta$ the unknown, $[\theta]$ its probabilitic distribution.
Consider some data $(A,B)$ taken as pieces of information. Via Bayes'rule one gets
$$[\theta|A,B]=\frac{[\theta,A,B]}{[A,B]}=\frac{[A,B|\theta]\times [\theta]}{[A,B]}\\
[\theta|A,B]=\frac{[A|\theta,B]\times[B|\theta]\times [\theta]}{[A,B]}$$
Focusing on these quantities as a function of the target $\theta$ only, we see that:
$$[{\theta}|A,B] \propto [A|\theta,B]\times[B|\theta]\times [\theta]$$
In the challenge, $\theta$ is a categorical variable refering eiter to the count class of wildfires (ranging from $1$ to $28$) in a given pixel at a certain time, or the corresponding burnt area or both. The available information $A$ stems from many various sources:
 - the neigbours because of the spatial coherence,
 - the previous category of the pixel (or its neighbours), as well as its next state due to some expected temporal behavior.
 - the 10 meteorological variables.
 - the proportions of the 18 land cover classes in the grid cell.
 When the information $A$ and the unknown $\theta$ are both categorical as in the first two cases, $A|\theta$ is a cross-table that can be empirically computed from the raw data table.
 When the information $A$ is continuous and the unknown $\theta$ fixed at a certain category, $A|\theta$ empirically correspond to a matrix of observations that could be modeled as a multivariate Gaussian realisation after suitable transformations.
 
 Assuming $[A,B|\theta]=[A|\theta]\times [B|\theta]$ i.e. that, given $\theta$, the pieces of information $A$ and $B$ are conditionnally independent would allow for sequential updating:
$$[{\theta}|A,B] \propto
[A|\theta]\times[B|\theta]\times [\theta]$$
 
 
 
## Priors by class of mean numbers of fires

We initialize probability distribution by grouping through classes of fires

```{r}
d <- data_train_DF %>% dplyr::select(IdNumber,classe_meanCNT,theta_CNT) %>% 
  arrange(IdNumber) 
truc= tibble(IdNumber=rep(0,11*29),classe_meanCNT=rep(1:11,29),theta_CNT=rep(1:29 ,each=11))
d_nest<- rbind(d,truc) %>% filter(!is.na(theta_CNT)) %>% group_by(classe_meanCNT) %>% nest
d_nest %>% arrange(classe_meanCNT) %>%  mutate(
      out= purrr::map(data,~{(table(.x$theta_CNT))}),
      p1=purrr::map_int(out,1),
      p2=purrr::map_int(out,2), 
      p3=purrr::map_int(out,3),
      p4=purrr::map_int(out,4),
      p5=purrr::map_int(out,5), 
      p6=purrr::map_int(out,6),
      p7=purrr::map_int(out,7),
      p8=purrr::map_int(out,8), 
      p9=purrr::map_int(out,9),
      p10=purrr::map_int(out,10),
      p11=purrr::map_int(out,11),
      p12=purrr::map_int(out,12), 
      p13=purrr::map_int(out,13),
      p14=purrr::map_int(out,14),
      p15=purrr::map_int(out,15), 
      p16=purrr::map_int(out,16),
      p17=purrr::map_int(out,17),
      p18=purrr::map_int(out,18), 
      p19=purrr::map_int(out,19),
      p20=purrr::map_int(out,20),
      p21=purrr::map_int(out,21),
      p22=purrr::map_int(out,22), 
      p23=purrr::map_int(out,23),
      p24=purrr::map_int(out,24),
      p25=purrr::map_int(out,25), 
      p26=purrr::map_int(out,26),
      p27=purrr::map_int(out,27),
      p28=purrr::map_int(out,28),
      p29=purrr::map_int(out,29)
      ) %>% 
      dplyr::select(-out,-data) -> dd
dd<-dd %>% ungroup() %>%  
  mutate(somme = apply(dplyr::select(.,starts_with("p")),1,sum)) %>% 
  group_by(classe_meanCNT) 


dd<- tibble(classe_meanCNT=dd$classe_meanCNT,dd[, 2:(2+28)]/dd$somme)

Proba<-data_train_DF %>% dplyr::select(IdNumber,classe_meanCNT,theta_CNT) %>% 
  arrange(IdNumber) %>% left_join(dd) %>% dplyr::select(-classe_meanCNT)
    
```

The tibble *Proba* now contains a prior distribution for CNT state to start with. We can compute its score.

```{r}
SCNT_cat=function(Obs, Pred,u_cnt=u_cnt,weights_cnt=weights_cnt) {
  
  # calculate the matrix with estimated exceedance probability of the severity thresholds:
  indicatrice_cnt=Pred
  prediction_cnt=t(apply(Pred,1, cumsum))
  
  for(k in 1:length(u_cnt)){
    Ind_k=Obs
    Ind_k[u_cnt[k]<Obs]<-0
    Ind_k[u_cnt[k]>=Obs]<-1
    indicatrice_cnt[,k]=Ind_k
  }
  
  #Computation of Scnt
#  weights_cnt=matrix(weights_cnt,ncol=1)
#  Scnt=sum(((indicatrice_cnt-prediction_cnt)^2%*%weights_cnt))
  Scnt=sum((as.matrix((indicatrice_cnt-prediction_cnt)^2)%*%matrix(weights_cnt,ncol=1)))
  
  return(Scnt)}


```


Some cleaning...
```{r}
perf0<-SCNT_cat(Obs=Proba %>% filter(!is.na(theta_CNT)) %>% pull(theta_CNT), 
         Pred=Proba %>% filter(!is.na(theta_CNT)) %>% dplyr::select(starts_with("p")) %>% 
           dplyr::select(-p29),
         u_cnt=u_cnt,weights_cnt=weights_cnt)
perf0
scores<-list(PriorSurClassesCNT=perf0)
l<-ls()
rm(list=l[!l%in% c("data_train_DF", "Proba","u_ba","u_cnt","weights_ba","weights_cnt","SCNT_cat","scores")])
```
Some other prior
```{r}
data_train_DF %>% pull(theta_CNT) %>% table()->tab
prior_CNT= as.numeric((tab/sum(tab)))
prior_CNT=cbind(data_frame(IdNumber=data_train_DF$IdNumber,
                           theta_CNT=data_train_DF$theta_CNT),
                as_data_frame(matrix(prior_CNT,nrow=length(data_train_DF$IdNumber),ncol=29,byrow = T) ))
#colnames(prior_CNT)<-colnames(Proba)
colnames(prior_CNT)<-c("IdNumber","theta_CNT", paste("p",1:29,sep=""))
perf0bis<-SCNT_cat(Obs=prior_CNT %>% filter(!is.na(theta_CNT)) %>% pull(theta_CNT), 
         Pred=prior_CNT %>% filter(!is.na(theta_CNT)) %>% dplyr::select(starts_with("p")) %>% 
           dplyr::select(-p29),
         u_cnt=u_cnt,weights_cnt=weights_cnt)
perf0bis
scores<-c(scores, list(SiFrequence=perf0bis))
Proba <-prior_CNT #ON demarre avec ce prior
```


## Bayesian updating in practice

First we write a function to update when the information is discrete.
```{r CalculProbaDiscrete}

CalculProbaDiscrete=function(d){
  # Calcul de la loi conditionnele [A|theta]
  dd<-d %>% filter(IdNumber !=IdNumber_A) %>% na.omit() %>% arrange(theta,A)
  Tab<- table(dd$theta,dd$A)
  A_Sachant_theta=t(Tab/matrix(apply(Tab,1,sum),nrow = 29,ncol=29) )  #(A en ligne, theta en colonne)
  ## Découpage en deux sous-tableaux
dquireste<-d %>% filter(!is.na(A)) %>% filter(!(IdNumber_A==IdNumber)) %>% arrange(A)
dinvariable <- d %>% filter(is.na(A) | (IdNumber_A==IdNumber)) %>% arrange(IdNumber)
dquireste %>% group_by(A) %>% summarize(n=n()) %>% pull(n)->n
##mise a jour bayesienne
M=matrix(A_Sachant_theta[1,1:29],nrow=n[1],ncol=29,byrow=T)
for (s in 2:29){M= rbind(M, matrix(A_Sachant_theta[s,1:29],nrow=n[s],ncol=29,byrow=T))
               }
M=M*(dquireste %>% dplyr::select(starts_with("p")))
#renormalisation
M=M/apply(M,1,sum)
dquireste<- bind_cols(dquireste %>% dplyr::select(-starts_with("p")),M)
dout<-bind_rows(dquireste,dinvariable) %>% arrange(IdNumber)
Proba<- dout %>% dplyr::select(IdNumber, theta, starts_with("p"))
}

```

We now update the probability of the CNT states with neighbors located at the left

```{r}
Proba=prior_CNT # on demarre avec ce prior
d <- data_train_DF %>% left_join(Proba) %>% arrange(IdNumber) %>%
  rename(IdNumber_A=IdNumber_left) %>% 
  rename(theta=theta_CNT) %>% 
  mutate(A=theta[IdNumber_A]) %>% 
  dplyr::select(IdNumber,IdNumber_A, theta,A, starts_with("p")) 

Proba=CalculProbaDiscrete(d)

Proba <-Proba %>% rename(theta_CNT=theta)

#cleaning
perf_left<-SCNT_cat(Obs=Proba %>% filter(!is.na(theta_CNT)) %>% pull(theta_CNT), 
         Pred=Proba %>% filter(!is.na(theta_CNT)) %>% dplyr::select(starts_with("p")) %>% 
           dplyr::select(-p29),
         u_cnt=u_cnt,weights_cnt=weights_cnt)
perf_left
scores<-c(scores, list(left=perf_left))
l<-ls()
rm(list=l[!l%in% c("data_train_DF", "Proba","u_ba","u_cnt","weights_ba","weights_cnt","SCNT_cat","scores","CalculProbaDiscrete")])
```

We now update the probability of the CNT states with neighbors located at the right

```{r}
d <- data_train_DF %>% left_join(Proba) %>% arrange(IdNumber) %>%
  rename(IdNumber_A=IdNumber_right) %>% 
  rename(theta=theta_CNT) %>% 
  mutate(A=theta[IdNumber_A]) %>% 
  dplyr::select(IdNumber,IdNumber_A, theta,A, starts_with("p")) 

Proba=CalculProbaDiscrete(d)

Proba <-Proba %>% rename(theta_CNT=theta)


#cleaning
perf_right<-SCNT_cat(Obs=Proba %>% filter(!is.na(theta_CNT)) %>% pull(theta_CNT), 
         Pred=Proba %>% filter(!is.na(theta_CNT)) %>% dplyr::select(starts_with("p")) %>% 
           dplyr::select(-p29),
         u_cnt=u_cnt,weights_cnt=weights_cnt)
perf_right
scores<-c(scores, list(right=perf_right))
l<-ls()
rm(list=l[!l%in% c("data_train_DF", "Proba","u_ba","u_cnt","weights_ba","weights_cnt","SCNT_cat","scores","CalculProbaDiscrete")])
```

With neighbors located North

```{r}
d <- data_train_DF %>% left_join(Proba) %>% arrange(IdNumber) %>%
  rename(IdNumber_A=IdNumber_up) %>% 
  rename(theta=theta_CNT) %>% 
  mutate(A=theta[IdNumber_A]) %>% 
  dplyr::select(IdNumber,IdNumber_A, theta,A, starts_with("p")) 

Proba=CalculProbaDiscrete(d)

Proba <-Proba %>% rename(theta_CNT=theta)

#cleaning
perf_north<-SCNT_cat(Obs=Proba %>% filter(!is.na(theta_CNT)) %>% pull(theta_CNT), 
         Pred=Proba %>% filter(!is.na(theta_CNT)) %>% dplyr::select(starts_with("p")) %>% 
           dplyr::select(-p29),
         u_cnt=u_cnt,weights_cnt=weights_cnt)
perf_north
scores<-c(scores, list(north=perf_north))
l<-ls()
rm(list=l[!l%in% c("data_train_DF", "Proba","u_ba","u_cnt","weights_ba","weights_cnt","SCNT_cat","scores","CalculProbaDiscrete")])
```

With neighbors located South

```{r}
d <- data_train_DF %>% left_join(Proba) %>% arrange(IdNumber) %>%
  rename(IdNumber_A=IdNumber_down) %>% 
  rename(theta=theta_CNT) %>% 
  mutate(A=theta[IdNumber_A]) %>% 
  dplyr::select(IdNumber,IdNumber_A, theta,A, starts_with("p")) 

Proba=CalculProbaDiscrete(d)

Proba <-Proba %>% rename(theta_CNT=theta)

#cleaning
perf_south<-SCNT_cat(Obs=Proba %>% filter(!is.na(theta_CNT)) %>% pull(theta_CNT), 
         Pred=Proba %>% filter(!is.na(theta_CNT)) %>% dplyr::select(starts_with("p")) %>% 
           dplyr::select(-p29),
         u_cnt=u_cnt,weights_cnt=weights_cnt)
perf_south
scores<-c(scores, list(south=perf_south))
l<-ls()
rm(list=l[!l%in% c("data_train_DF", "Proba","u_ba","u_cnt","weights_ba","weights_cnt","SCNT_cat","scores","CalculProbaDiscrete")])
```
# Prise en compte des variables continues comme source d'information

J suggest a Normal quantile transformation : first we bin each of them to get the empirical cumulative distribution and then  transform  into a Gauss variate. A PCA is them performed to reduce dimension

```{r}
LC<- data_train_DF %>% arrange(theta_CNT) %>% dplyr::select(.,starts_with("lc")) %>% as.matrix()

for(j in 1:18){
  Fn<-ecdf(LC[,j])
LC[,j]= qnorm(0.99*Fn(LC[,j]))
}
#range(LC)
#var(LC)
SVD=svd(LC)
plot(1:18,cumsum(SVD$d/sum(SVD$d)))

d<- data_train_DF %>% arrange(theta_CNT) %>% dplyr::select(theta_CNT,IdNumber) %>% cbind(LC) %>% na.omit()
n=d %>% group_by(theta_CNT) %>% summarize(n=n()) %>% pull(n)
LC<- d %>% dplyr::select(.,starts_with("lc")) %>% as.matrix()


csn=cumsum(n)
ListeMu=list(mu=colMeans(LC[1:n[1],]))
for (i in 1:(29-1)){  debut = csn[i]+1
                  fin= csn[i+1]
                  ListeMu=c(ListeMu, list(mu=colMeans(LC[debut:fin,])))
}
ListeSigma=list(Sigma=var(LC[1:n[1],]))
for (i in 1:(29-1)){  debut = csn[i]+1
                  fin= csn[i+1]
                  ListeSigma=c(ListeSigma, list(Sigma=var(LC[debut:fin,])))
                  }
ListeP=list(P=solve(var(LC[1:n[1],])))
for (i in 1:(29-1)){  debut = csn[i]+1
                  fin= csn[i+1]
                  ListeP=c(ListeP, list(P=solve(0.001*diag(18)+var(LC[debut:fin,]))))
                  }
#svd(0.001*diag(18)+var(LC[debut:fin,]))$d

multinorm <- function(theta, x){
  P=ListeP[[theta]]
  m=ListeMu[[theta]]
  f=det(P)^0.5*exp(-0.5*(x-m)%*%P%*%(x-m))
}

 d<- d %>%left_join(prior_CNT) %>% filter(!is.na(theta_CNT)) 
 LC<- d %>% dplyr::select(.,starts_with("lc")) %>% as.matrix()
 M= d %>% dplyr::select(.,starts_with("p"))
#  A=0*M
# for (i in 1: 483983){A[i,1]=multinorm (theta=1, x=as.vector(LC[i,]))
# if ((i %% 10000)==0) print(i) }
 # theta= d %>% pull(theta_CNT)
 
 
 for (i in 1: 483983){ 
       for ( j in 1:29) { M[i,j]=multinorm(theta=j, x=LC[i,])
                         if ((i %% 100000)==0) print(c(j,i))
       }}
 save(list="M",file="M.Rdata")

 
```



